\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kaushik2019learning,gardner2020contrast}
\citation{gardner2020contrast}
\citation{sakaguchi2019winogrande}
\citation{wieting2017paranmt}
\citation{wieting2017paranmt}
\citation{wieting2017paranmt}
\citation{zhang2019paws,mccoy2019right}
\citation{zhang2019paws,mccoy2019right}
\bibdata{anthology,ref}
\bibcite{gardner2020contrast}{{1}{2020}{{Gardner et~al.}}{{Gardner, Artzi, Basmova, Berant, Bogin, Chen, Dasigi, Dua, Elazar, Gottumukkala et~al.}}}
\bibcite{kaushik2019learning}{{2}{2019}{{Kaushik et~al.}}{{Kaushik, Hovy, and Lipton}}}
\bibcite{Khashabi2020MoreBF}{{3}{2020}{{Khashabi et~al.}}{{Khashabi, Khot, and Sabharwal}}}
\bibcite{mccoy2019right}{{4}{2019}{{McCoy et~al.}}{{McCoy, Pavlick, and Linzen}}}
\bibcite{sakaguchi2019winogrande}{{5}{2019}{{Sakaguchi et~al.}}{{Sakaguchi, Bras, Bhagavatula, and Choi}}}
\bibcite{suhr2018corpus}{{6}{2018}{{Suhr et~al.}}{{Suhr, Zhou, Zhang, Zhang, Bai, and Artzi}}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:relate}{{4}{1}{Related Work}{section.4}{}}
\newlabel{sec:discuss}{{5}{1}{Discussion and Conclusion}{section.5}{}}
\newlabel{fig:mturk_instruction}{{1}{1}{A sample labeling task. For each round of labeling, the annotator is given the original instance (and its label) as a reference, and they are tasked to label three variations of the instance by (1) grammatically validity and (2) classification task label. A more detailed instruction is in \S \ref {appendix:label_instruct}. \wts {This is placeholder screenshot. Change width/height ratio, choose a better example}\relax }{figure.caption.2}{}}
\bibcite{wieting2017paranmt}{{7}{2017}{{Wieting and Gimpel}}{{}}}
\bibcite{zhang2019paws}{{8}{2019}{{Zhang et~al.}}{{Zhang, Baldridge, and He}}}
\bibstyle{acl_natbib}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:ctrltag}{{1}{2}{A list of \tagstrs used for semantically driving the GPT-2 generation, the model generated examples, and the training datasets that contains most of the corresponding patterns. \wts {Change all the examples to be on an identical sentence, not all different cases. And consider further annotate the tags based on whether they just do semantic change or also syntactic change.}\relax }{table.caption.1}{}}
\citation{gardner2020contrast}
\citation{kaushik2019learning}
\citation{sakaguchi2019winogrande}
\citation{wieting2017paranmt}
\citation{zhang2019paws}
\citation{mccoy2019right}
\newlabel{appendix:train_data}{{A}{3}{Datasets for GPT-2 Finetuning}{appendix.A}{}}
\newlabel{appendix:label_instruct}{{B}{3}{Labeling Instructions \& Quality}{appendix.B}{}}
\citation{Khashabi2020MoreBF}
\citation{kaushik2019learning}
\citation{gardner2020contrast}
\citation{suhr2018corpus}
\newlabel{table:gpt_train_stats}{{2}{4}{The datasets used for finetuning the GPT-2 perturbation model, and the \tagstr distributions.\relax }{table.caption.4}{}}
\newlabel{fig:mturk_instruction}{{2}{5}{A sample instruction for the \nli task, with annotators providing labels based for the perturbed hypotheses (\emph {New S2}). Instructions are similar for \qqp and \sst , except for the label definitions and the examples. \wts {Change to hypothesis screenshot.}\relax }{figure.caption.11}{}}
