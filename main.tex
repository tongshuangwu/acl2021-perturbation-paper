%
% File acl2020.tex
%
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{latexsym}

\renewcommand{\UrlFont}{\ttfamily\small}
\usepackage{amsmath,amsthm,amssymb}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

\usepackage{paralist}
\usepackage{verbatim}
\usepackage[normalem]{ulem}
\usepackage[vlined,ruled,linesnumbered]{algorithm2e}
\usepackage{makecell}
\usepackage{txfonts}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor,colortbl}
\usepackage{color,soul}
\usepackage{multirow}

\usepackage[T1]{fontenc}
\usepackage{bbold}
\usepackage{pifont}% http://ctan.org/pkg/pifont


\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.
\renewcommand{\ttdefault}{txtt}
\newcommand\BibTeX{B\textsc{ib}\TeX}
%\newcommand*{\emailfont}{\fontfamily{pcr}\selectfont}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\newcommand{\colbox}[2]{
\begingroup
  \setlength{\fboxsep}{0pt}%  
  \colorbox{#1}{#2\/}%\reducedstrut
\endgroup}

 
\newcommand{\veryshortarrow}[1][3pt]{\mathrel{%
   \hbox{\rule[\dimexpr\fontdimen22\textfont2-.2pt\relax]{#1}{.4pt}}%
   \mkern-4mu\hbox{\usefont{U}{lasy}{m}{n}\symbol{41}}}}
   
  
\definecolor{caddback}{rgb}{0.90, 0.98, 0.96}
\definecolor{cadd}{rgb}{0, 0.47, 0.34}
\definecolor{cdelback}{rgb}{1, 0.94, 0.92}
\definecolor{cdel}{rgb}{0.83, 0.32, 0.16}
\def \arrow{$\veryshortarrow$}
\newcommand{\add}[1]{\colbox{caddback}{{\color{cadd}#1\xspace}}} %
\newcommand{\remove}[1]{\colbox{cdelback}{{\color{cdel}#1\xspace}}}%
\newcommand{\swap}[2]{\remove{#1} \arrow\add{#2}}
\newcommand{\changed}[2]{{#1}\arrow ~\add{#2}}
\newcommand{\ctrltag}[1]{\texttt{#1}\xspace}


\definecolor{cexample}{rgb}{0.23, 0.30, 0.45}
\newcommand{\exinline}[1]{ {\color{cexample}``#1''\xspace}}
\newcommand{\fillin}[1]{ {\color{cexample}#1\xspace}}

\newcommand{\fontsmall}{\fontsize{9pt}{11pt}\selectfont}
\newcommand{\fontnormal}{\fontsize{10pt}{12pt}\selectfont}
\fboxrule=0.1pt
\newcommand{\ebox}[1]{%
	\medskip
	\noindent\fcolorbox{gray}{white}{
		\begin{minipage}{0.95\linewidth}
			\fontsmall
			%\begin{internallinenumbers}
			%\resetlinenumber
			{#1}
			%\end{internallinenumbers}
		\end{minipage}
	}
	\medskip
}

% [(0.166, 'opposing '), (0.099, 'team '), (0.027, 'by '), (0.026, 'quarterback '), (0.024, 'The '), (0.024, 'is '), (0.024, '. '), (0.023, ' '), (0.023, 'about '), (0.023, 'to '), (0.023, 'be '), (0.023, 'tackled '), (0.019, 'the '), (-0.0, ' ')]
%#eef5fa
%#daeaf5
%#c6deef
%#b2d2e9
%#9ec7e4
%#8abbde

\definecolor{ctemplate}{rgb}{0.23, 0.30, 0.45}
%\definecolor{ctemplate}{rgb}{0.23, 0.30, 0.45}
\definecolor{cword}{rgb}{0, 0, 0.7}
\newcommand{\BLANK}{\texttt{ {\color{cword}[BLANK]} }}

% format
\newcommand{\clabel}[1]{\emph{#1}\xspace}

% constants
\newcommand{\sysname}{Aditor\xspace}

\newcommand{\mturkurl}{\url{https://tongshuangwu.github.io/perturb-exp-ui/?assignmentId=1&platform=standalone&debug=debug&task=nli}}
\newcommand{\tagstr}{control code\xspace}
\newcommand{\Tagstr}{Control code\xspace}
\newcommand{\tagstrs}{control codes\xspace}


\newcommand{\cmark}{{\ding{51}}}%
\newcommand{\xmark}{{\ding{55}}}%
\newcommand{\qmark}{{\textsf{?}}}%

\newcommand{\perturbtoken}{\texttt{<|perturb|>}\xspace}%
\newcommand{\stoptoken}{\texttt{[SEP]}\xspace}%



\newcommand{\eg}{\emph{e.g.,}\xspace}%
\newcommand{\ie}{\emph{i.e.,}\xspace}

% tasks
\newcommand{\nli}{NLI\xspace}
\newcommand{\sst}{Sentiment\xspace}
\newcommand{\qqp}{QQP\xspace}

\def \dsst{SST-2\xspace}
\def \dqqp{QQP\xspace}
\def \dnli{SNLI\xspace}

% annotations
\newcommand{\note}[2]{\xspace{\color{#1}[ #2 ]}\xspace}
%\newcommand{\note}[2]{}
\newcommand{\wts}[1]{\note{violet}{Sherry: #1}}









% teal, cyan
\title{\sysname: Towards Automated Perturbation Generation \\for Evaluation, Data Augmentation, and Explanation}
\begin{comment}
\author{
Tongshuang Wu \\
  University of Washington \\
  \texttt{wtshuang@uw.edu} \\\And
Marco Tulio Ribeiro \\
  Microsoft Research \\
  \texttt{marcotcr@gmail.com} \\\And
Jeffrey Heer \\
  \texttt{jheer@uw.edu} \\\And
Jeffrey Heer \\
  \texttt{jheer@uw.edu} \\
}
\end{comment}

\author{
\makecell{
Tongshuang Wu$^{1}$ ~~~~~~~ 
Marco Tulio Ribeiro$^{2}$ ~~~~~~~ 
Jeffrey Heer$^{1}$ ~~~~~ 
Daniel S. Weld$^{1}$}  \\ 
$^{1}$Allen School, University of Washington\hspace{5mm}
$^{2}$Microsoft Research\hspace{5mm} \\ 
\href{mailto:wtshuang@cs.uw.edu}{\texttt {wtshuang@cs.uw.edu}}
\hspace{2mm}
\href{mailto:marcotcr@microsoft.com}{\texttt {marcotcr@gmail.com}}
\hspace{2mm}
\href{mailto:dan@cs.washington.edu}{\texttt {\{jheer,weld\}@cs.uw.edu}}
}


\date{}

\begin{document}
\maketitle
\begin{abstract}
Minimal perturbations is effective for evaluating and calibrating model decision boundaries, but existing generation methods either cover limited linguistic patterns, or are hard to scale.
We explore language-model based perturbation generation.
We define the training prompts with two information:
To enable targeted inspection, we use \emph{\tagstrs} to indicate \emph{how} to change a sentence with defined based on common linguistic capabilities, and \emph{where} to change by blanking certain linguistic features.
We finetune GPT-2 on a combination of multiple existing datasets,  and verify its usefulness of the generations in three applications:
(1) As contrast sets, the model performance decreases up to 19.3 points on them compared to on the original test set, revealing model inefficiencies.
(2) As counterfactual data augmentation, they improve models on data slices, and models perform better on out-of-domain datasets, challenge sets, or pass more behavioral tests.
\wts{Number?}
(3) They also supply existing explanations and more effectively demonstrate the impact certain text.
\end{abstract}

\input{sections/intro}
\input{sections/model}
\input{sections/use_label}
\input{sections/use_explanation}
\input{sections/relate}
\input{sections/conclusion}

\bibliography{ref}
\bibliographystyle{acl_natbib}

\clearpage
\newpage

\appendix
\input{sections/app_train_datasets}
\input{sections/app_perturb_applications}
\input{sections/app_label_instruction}
\input{sections/app_examples}
\input{sections/app_perturb_similarity}

\end{document}
