\section{Task Formalization \& Modeling}

\begin{comment}
* Define the task
- Some math
- Several different application domains
    - augmentation
    - adversarial attack
    - extend data
    - counterfactual explanation
- Importance of where to change and how to change

* How to train
- Compute control tags
- Special tokens

* Use existing datasets
- Why each dataset 
- Data distribution [maybe appendix]

* Training hyperparameters

* Evaluations
- Filtering
- Diversity
\end{comment}

\newcommand{\tagdefine}[1]{\emph{{\color{darkgray}#1} }}
\renewcommand{\arraystretch}{1.1}
\begin{table*}
\small
\centering
\begin{tabular}{p{0.11\linewidth} p{0.6\linewidth}  p{0.2\linewidth}}
\toprule
\textbf{\Tagstr} & \textbf{Definitions and Examples} & \textbf{Datasets} \\ 
\midrule
\ctrltag{negation}
    & You'd \swap{figure that out}{never know} by watching it though.
    & \cite{kaushik2019learning, gardner2020contrast}
\\ \midrule
\ctrltag{quantifier}
    & Where can buy Jordan \swap{5}{6} shoes?
    & \cite{gardner2020contrast}
\\ \midrule
\ctrltag{lexical}
    & \tagdefine{Changing just one word or noun chunks without breaking the POS tags.} \newline
      He found them \swap{exciting}{dull}.
    & \cite{sakaguchi2019winogrande}
\\ \midrule
\ctrltag{resemantic}
    & \tagdefine{To replace short phrases or clauses without affecting the parsing tree.}\newline
      How do you \swap{access Snapchat}{brand yourself} online?
    & \cite{wieting2017paranmt}
\\ \midrule
\ctrltag{insert}
    & \tagdefine{To add constraints without affecting the parsing structure of other parts.} \newline
      I liked a \add{Bangali} boy.
    & \cite{wieting2017paranmt}
\\ \midrule
\ctrltag{delete}
    & \tagdefine{To remove constraints without affecting the parsing structure of other parts.} \newline
    The lawyers paid \remove{the tourists}.
    & \cite{wieting2017paranmt}
\\ \midrule
\ctrltag{restructure}
    & \tagdefine{To alter the dependency tree structure, e.g., changing from passive to positive.} \newline
    How do you study \swap{well}{animals}?
    & \cite{zhang2019paws, mccoy2019right}
\\ \midrule
\ctrltag{shuffle}
    & \tagdefine{To move (or swap) key phrases or entities around the sentence.} \newline
    Why do so many more \swap{women}{men} commit suicide than \swap{men}{women}?
    & \cite{zhang2019paws, mccoy2019right}
\\
\bottomrule
\end{tabular}
\caption{A list of \tagstrs used for semantically driving the GPT-2 generation, the model generated examples, and the training datasets that contains most of the corresponding patterns. \wts{Change all the examples to be on an identical sentence, not all different cases. And consider further annotate the tags based on whether they just do semantic change or also syntactic change.}}
\label{table:ctrltag}
\end{table*}


In response to the objectives, we form the perturbation as a text generation task.
Given a paired sentence $x$ and $x'$, We form the training prompts as 


and finetune GPT-2 model


We combined multiple existing NLP datasets in finetuning our GPT-2 perturbation model. 


All datasets provide pairs of sentences $(s_1, s_2)$.
We first compute the \tagstrs introduced in Table~\ref{table:ctrltag}, based on the POS-tag and parsing structure heuristics.
Then, to construct the training texts, we concatenate the two sentences, the control tag, and the special tokens. 


To control \emph{where to change}