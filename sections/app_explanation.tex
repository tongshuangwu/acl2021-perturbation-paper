\section{Additional Details to Explanations \S\ref{sec:app_explain}}
\label{appendix:explanation}


\subsection{Ranking Details}



\paragraph{SHAP complement as local explanation}
Because the SHAP weights reflect the average effect of masking a token $t$, instead of individual abnormal counterfactuals, we focus on \emph{word features that are abnormal on average.}
That is, it is abnormal if there is a mismatch between the importance of the changed word features and the model behavior, in light of \emph{all counterfactuals} that have those features.

In this case, the expected change in prediction of perturbing a token $t$ is the SHAP weight on it $\hat{d}(t, x) = w(t)$; The actual prediction change is the weighted average of $|f_p(x)-f_p(\xp)|$ for all the $\xp$ that affect $t$, with the weight is the number of words modified in $\xp$. 
Intuitively, the more words changed in $\xp$, the less effect each word has.
More formally, for a given $x$ and its $\xp$-s, we use $r(\xp)$ to denote the set of words replaced or deleted from $x$ in $x \rightarrow \xp$.
We group the counterfactuals based on their affected words $G_t = \{\xp\ |\ t \in r(\xp)\}$. $d(t, x)$ then becomes:
$$d(t, x) = \frac{1}{|G_t|+1} \left(w(t) + \sum_{\xp \in G_t} \frac{|f_p(x)-f_p(\xp)|}{|r(\xp)|}\right)$$
We add the additional SHAP weight $w(t)$ as a smoothing factor to punish dominating outlier $\xp$-s.

We first find the abnormal tokens $t_l = \argmax \Delta d(t, x)$ and $t_s = \argmin d(t, x)$, and use the most extreme cases within the groups of $G_{t_l}$ and $G_{t_s}$ as the concrete counterfactual explanations, based on their prediction change $d(\xp, x) = |f_p(x)-f_p(\xp)|$, and the aggregated SHAP weights of all the changed tokens:
$$\xp_l = \argmax_{\xp \in G_{t_l}} \left( |f_p(x)-f_p(\xp)| - \sum_{u\in r(\xp)} w(u) \right)$$ 



\paragraph{Global explanation}
To enable the grouping, we first featurize each counterfactual $\xp$ with respect to its original instance $x$, using 
(1) its \tagstr (\fexptag{negation} for the example in Figure~\ref{fig:blank}), 
(2) its remove phrases \fexpfrom{kids}, 
(3) its added phrases \fexpto{not}, \fexpto{children}, and 
(4) the combined template \fexptemp{\swap{kids}{children}}.
For tokens involving multiple changes, we featurize both the primary and the combined changes, and so the example in Figure~\ref{fig:blank} also have additional features like \texttt{\fexptag{negation} \& \fexptag{lexical}}.

For each feature $h$ we compute the its prediction change rate over all the perturbations $(x, \xp) \in G_{h}$ that have the said feature, and compute the probability of the predicted label changes: $Pr(y_1, y_2) = |G_h^{y_1\rightarrow y_2}|/|G_h|$, where $ G_h^{y_1\rightarrow y_2} = \{ (x, \xp)\ |\ (x, \xp) \in |G_h|, f(x)=y_1, f(\xp) = y_2 \}$.
The abnormality of a feature $h$ is represented by the entropy of the prediction change:
$$I_h = -\sum_{y_1 \in Y, y_2 \in Y} Pr(y_1, y_2) \cdot \log Pr(y_1, y_2)$$
We then find the abormal feature with $\hat{h} = \argmin I_h$.



\paragraph{User Study Details}

The instruction is in X, the labeling UI in X.