\section{Related Work}
\label{sec:relate}

Some prior work in training and evaluation relies on humans to generate counterfactuals from scratch~\cite{gardner2020contrast, teney2020learning, kaushik2019learning}. 
Our experiments in \S\ref{sec:app_label} indicate that asking humans to \emph{label} \sysname{} counterfactuals yields similar or better results at a lower cost, which motivates an exploration of a mixture of manual and semi-automated generation. 
Similarly, prior work on analysis relies on experts to create individual counterfactuals or perturbation functions~\cite{wu2019errudite, checklist:acl20}. 
In \S\ref{sec:app_err_analysis}, we show that \sysname{} enhances current practice by generating multiple counterfactuals that might have been overlooked, and by providing abstractions that allow for new kinds of analyses.

Prior work on automatically generating counterfactuals typically has a narrower scope in terms of the relationships $x \veryshortarrow \xp$.
For example, adversarial generators aim to maintain semantics while changing model predictions~\cite{ribeiro2018semantically, iyyer2018adversarial, li2020contextualized}, whereas concurrent work to our own~\cite{madaan2020generate, ross2020explaining} automatically generates $\xp$ that change predictions for explanation or analysis, with no constraints on semantics.
However, as shown in \S\ref{sec:app_label}--\S\ref{sec:app_err_analysis}, a \emph{mix} of label-preserving and label-flipping counterfactuals generated by \sysname is quite useful for training, evaluation, explanation, and analysis. 
Further, general-purpose counterfactuals may lead to serendipitous discoveries (\S\ref{sec:app_err_analysis}), especially as \sysname is not finetuned to the target domain (and thus less liable to merely replicate what is already there).
Finally, by allowing control through \tagstrs and \texttt{[BLANK]}s, \sysname{} supports human-generator collaboration, where the human specifies the desired changes (\eg perturb \emph{the sentence subject}).
Such collaboration is hard to imagine using automatic generators with no control or with coarser control through predefined style attributes or labels~\cite{madaan-etal-2020-politeness, malmi-etal-2020-unsupervised}. To our knowledge, prior work on controlled generation~\cite{ctrl, pplm} does not address \emph{counterfactual} generation.


% Counterfactuals in various applications differ by their impact on the groundtruth and model prediction labels.
% Those changing the groundtruth are mostly used for counterfactual training~\cite{kaushik2019learning, teney2020learning} and evaluation~\cite{gardner2020contrast, checklist:acl20}.
% As mentioned in \S\ref{sec:intro}, these counterfactuals rely heavily on human creativity and are expensive to collect.
% Though it is cheaper to automate the process with parsing templates~\cite{li2020linguistically}, usually the templates are only applicable to a small subset of data.
% \citet{wang2020robustness} also proposed to automatically flip the groundtruth by replacing causal word features with their antonyms.
% However, they acknowledged that the method supplies limited tasks, as ``antonym'' is only well-defined in sentiment analysis.
% We achieve a middle ground, showing that the team of \sysname and a human moderator collect data more effectively.

% On the other hand, multiple prior works automatically generate counterfactuals that flip model predictions.
% These methods are used for counterfactual explanations.
% For example, \citet{kang2020counterfactual} guided word replacement with model prediction probabilities.
% Our concurrent work, GYC~\cite{madaan2020generate} and MiCE~\cite{ross2020explaining} further enable phrase replacement through language models (GPT-2 or t5).
% However, these methods leave out prediction-persistent explanations, which are also important as shown in \S\ref{sec:app_explain}.
% If collected with additional constraints on semantic persistence~\cite{morris2020textattack, alzantot-etal-2018-generating}, the prediction-flipping counterfactuals become adversarial examples.
% Despite the apparent similarities between explanations and adversarials, to the best of our knowledge, adversarial generation is still mostly through word replacement~\cite{alzantot2018generating, garg2020bae, li2020contextualized} or paraphrasing~\cite{iyyer2018adversarial, malandrakis-etal-2019-controlled}, and has yet to take advantage of language models.
% Given the shared properties, a general-purpose model like \sysname may be more reasonable than methods tailored to specific applications.

% Moreover, the emphasis on \emph{labels} compresses a large set of diverse changes (\eg negations and antonym replacements both flip labels in sentiment analysis), and therefore hinders the definition and queryiig of desired counterfactuals.
% We instead design \sysname's controls to be task (label)-agnostic and finer-grained.
% Such controls additionally support applications that require specifications on where and how to perturb, \eg open-ended error analysis~\cite{wu2019errudite} where contrasting similar counterfactuals is essential (\S\ref{sec:app_err_analysis}).


