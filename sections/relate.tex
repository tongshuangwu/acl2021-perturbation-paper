\section{Related Work}
\label{sec:relate}

\textbf{The applications of counterfactuals.}
Counterfactuals in NLP are most broadly used for model training, evaluation, and explanation.
In training, counterfactuals usually augment the training data to improve model stability~\cite{Wu2019ConditionalBC, Wei2019EDAED, Kumar2020DataAU} and generalizability.
\citet{kaushik2019learning} and \citet{teney2020learning} showed that counterfactual augmentations help mitigate the weights of spurious features.
%\citet{teney2020learning} further proposed to treat instances in pairs to emphasize the difference in the training process. 
%Our data can also support such experiments.
Evaluation focuses on similar aspects as training, mostly through adversarial attacks~\cite{Song2020UniversalAA}, contrast sets~\cite{kaushik2019learning} and challenge sets~\cite{Geiger2019PosingFG, liu-etal-2019-inoculation}.
We show the automatically generated counterfactuals are also useful for training and evaluation.

Counterfactuals also naturally support model explanations, as ``explanations are sought in response to particular counterfactual cases or foils''~\cite{miller}.
Popular feature importance attribution methods like SHAP~\cite{NIPS2017_7062} or LIME~\cite{Ribeiro2016WhySI} all retrieve token importance through masking, which can be viewed as a form of (incomplete) counterfactual.
Some work also explores directly presenting simple counterfactual examples~\cite{hase2020evaluating, vig2020causal, kang2020counterfactual}.
We explore the ranking of such examples, and combine them with existing feature attribution methods.
%Perturbation is also used for explanations, but the use is much less prominent compared to structured data.
%While counterfactual explanations have been widely advocated in structured data, the use of it in text is not yet clear. Some papers tried generation, but didn't articulate the use. %We follow the structure of X to have both counter-factual and semi-factual. 

\noindent\textbf{Counterfactual generation.}
Existing generation methods are usually for particular applications.
Most automated ones are for adversarial examples. 
They enumerate through candidate word replacements~\cite{alzantot2018generating, garg2020bae, alzantot2018generating, andreas2019good} or paraphrases~\cite{iyyer2018adversarial, malandrakis-etal-2019-controlled} that can maintain semantic meanings while exposing model errors.
The exhaustive search is hard for people to scale to~\cite{ribeiro2018sear}.
On the other hand, those evaluating and improving model decision boundaries lean towards manual rewrites and perturbation functions~\cite{checklist:acl20}.
Such methods cover more diverse patterns, but the process is costly, and relies heavily on human creativity and domain expertise.
Moreover, though human annotators also share strategies like negation, subject-object swapping~\cite{kaushik2019learning, gardner2020contrast}, the strategies have yet to be captured for targeted use.
Template-based methods~\cite{mccoy2019right, nie2019analyzing} are more systematic and cost-effective, but usually are only applicable on a small amount of data (\eg \citet{li2020linguistically} covered 20\% NLI data.)

Closest to ours, \citet{madaan2020generate} generated diverse and plausible counterfactuals with controlled text generation~\cite{Dathathri2020Plug}, on top of GPT-2.
However, their \emph{controls} are strictly driven by the known classifier at hand (\eg a sentiment classifier is required to establish the sentiment change in $x\rightarrow \xp$), limiting the use case to model evaluation.
We unify the generation for different use cases and enable task-agnostic controls, which bridges the scalability and diversity.
We only distinguish the generated ones through posterior constraints~\cite{morris2020textattack, alzantot-etal-2018-generating}.







