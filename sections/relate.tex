\section{Related Work}
\label{sec:relate}

Counterfactuals in various applications differ by their impact on the groundtruth and model prediction labels.
Those changing the groundtruth are mostly used for counterfactual training~\cite{kaushik2019learning, teney2020learning} and evaluation~\cite{gardner2020contrast, checklist:acl20}.
As mentioned in \S\ref{sec:intro}, these counterfactuals rely heavily on human creativity and are expensive to collect.
Though it is cheaper to automate the process with parsing templates~\cite{li2020linguistically}, usually the templates are only applicable to a small subset of data.
\citet{wang2020robustness} also proposed to automatically flip the groundtruth by replacing causal word features with their antonyms.
However, they acknowledged that the method supplies limited tasks, as ``antonym'' is only well-defined in sentiment analysis.
We achieve a middle ground, showing that the team of \sysname and a human moderator collect data more effectively.

On the other hand, multiple prior works automatically generate counterfactuals that flip model predictions.
These methods are used for counterfactual explanations.
For example, \citet{kang2020counterfactual} guided word replacement with model prediction probabilities.
Our concurrent work, GYC~\cite{madaan2020generate} and MiCE~\cite{ross2020explaining} further enable phrase replacement through language models (GPT-2 or t5).
However, these methods leave out prediction-persistent explanations, which are also important as shown in \S\ref{sec:app_explain}.
If collected with additional constraints on semantic persistence~\cite{morris2020textattack, alzantot-etal-2018-generating}, the prediction-flipping counterfactuals become adversarial examples.
Despite the apparent similarities between explanations and adversarials, to the best of our knowledge, adversarial generation is still mostly through word replacement~\cite{alzantot2018generating, garg2020bae, li2020contextualized} or paraphrasing~\cite{iyyer2018adversarial, malandrakis-etal-2019-controlled}, and has yet to take advantage of language models.
Given the shared properties, a general-purpose model like \sysname may be more reasonable than methods tailored to specific applications.

Moreover, the emphasis on \emph{labels} compresses a large set of diverse changes (\eg negations and antonym replacements both flip labels in sentiment analysis), and therefore hinders the definition and querying of desired counterfactuals.
We instead design \sysname's controls to be task (label)-agnostic and finer-grained.
Such controls additionally support applications that require specifications on where and how to perturb, \eg open-ended error analysis~\cite{wu2019errudite} where contrasting similar counterfactuals is essential (\S\ref{sec:app_err_analysis}).


